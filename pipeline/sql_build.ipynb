{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from opentrons import robot, containers, instruments\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine,Column,Integer,String,ForeignKey,Table,Text,inspect,desc\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker,relationship\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import getch\n",
    "\n",
    "from config import *\n",
    "from db_config import *\n",
    "\n",
    "## Generate the SQL Database from json files and plate maps\n",
    "session = build_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = session.query(Part).filter(Part.part_id == 'BBF10K_000402').first()\n",
    "# print(test.part_id,test.fragments[0].wells[0].address)\n",
    "\n",
    "# test = session.query(Part).filter(Part.part_id == 'BBF10K_000403').first()\n",
    "# print(test.part_id,test.fragments[0].wells[0].address)\n",
    "\n",
    "# for part in session.query(Part).join(Fragment,Part.fragments).join(Well,Fragment.wells)\\\n",
    "#             .filter(Fragment.fragment_name.like('BBF10K_00000%'))\\\n",
    "#             .filter(Well != None).order_by(Part.part_id):\n",
    "#     print(part.part_id)\n",
    "\n",
    "# for part in session.query(Part).filter(Part.part_id.like('BBF10K_0000%')).order_by(Part.part_id):\n",
    "#     print(part.status)\n",
    "\n",
    "# for part in session.query(Part):\n",
    "#     no_build = False\n",
    "#     for frag in part.fragments:\n",
    "#         if not frag.wells:\n",
    "#             no_build = True\n",
    "#     if not no_build:\n",
    "#         part.change_status('received')\n",
    "\n",
    "\n",
    "# for part in session.query(Part).filter(Part.part_id.like('BBF10K_0000%')).order_by(Part.part_id):\n",
    "#     print(part.part_id,part.status)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ============================================\n",
    "## Take in required information\n",
    "## ============================================\n",
    "\n",
    "# Set starting paths\n",
    "# BASE_PATH is defined in the config file\n",
    "PIPELINE_PATH = BASE_PATH + \"/pipeline\"\n",
    "BUILDS_PATH = BASE_PATH + \"/builds\"\n",
    "DATA_PATH = BASE_PATH + \"/data\"\n",
    "\n",
    "# # Load files\n",
    "# parser = argparse.ArgumentParser(description=\"Resuspend a plate of DNA on an Opentrons OT-1 robot.\")\n",
    "# parser.add_argument('-r', '--run', required=False, action=\"store_true\", help=\"Send commands to the robot and print command output.\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "## ============================================\n",
    "## ESTABLISH INITIAL FUNCTIONS\n",
    "## ============================================\n",
    "def change_height(container,target):\n",
    "    '''Allows for real-time calibration of the p10 single height'''\n",
    "    x = 0\n",
    "    print(\"Change height - s-g:up h-l:down x:exit\")\n",
    "    while x == 0:\n",
    "        c = getch.getch()\n",
    "        if c == \"s\":\n",
    "            p10.robot._driver.move(z=20,mode=\"relative\")\n",
    "        elif c == \"d\":\n",
    "            p10.robot._driver.move(z=5,mode=\"relative\")\n",
    "        elif c == \"f\":\n",
    "            p10.robot._driver.move(z=0.5,mode=\"relative\")\n",
    "        elif c == \"g\":\n",
    "            p10.robot._driver.move(z=0.1,mode=\"relative\")\n",
    "        elif c == \"h\":\n",
    "            p10.robot._driver.move(z=-0.1,mode=\"relative\")\n",
    "        elif c == \"j\":\n",
    "            p10.robot._driver.move(z=-0.5,mode=\"relative\")\n",
    "        elif c == \"k\":\n",
    "            p10.robot._driver.move(z=-5,mode=\"relative\")\n",
    "        elif c == \"l\":\n",
    "            p10.robot._driver.move(z=-20,mode=\"relative\")\n",
    "        elif c == \"x\":\n",
    "            x = 1\n",
    "    p10s.calibrate_position((container,target.from_center(x=0, y=0, z=-1,reference=container)))\n",
    "\n",
    "def well_addresses():\n",
    "    '''Generates a list of well address A1-H12'''\n",
    "    letter = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]\n",
    "    number = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\"]\n",
    "    target_well = []\n",
    "    temp_well = 0\n",
    "    for n in number:\n",
    "        for l in letter:\n",
    "            temp_well = l + n\n",
    "            target_well.append(temp_well)\n",
    "    return target_well\n",
    "\n",
    "def change_plates(current_plates):\n",
    "    '''Allows the user to swap plates in the middle of a protocol'''\n",
    "    source_plates = {}\n",
    "    plate_locations = list(zip(pd.unique(current_plates),SOURCE_SLOTS[:len(current_plates)]))\n",
    "    print(\"plate_locations\",\"\\n\", plate_locations)\n",
    "    input(\"Switch out plates for those listed. Press enter when ready.\")\n",
    "    for plate, slot in plate_locations:\n",
    "        source_plates[plate] = containers.load('96-flat', slot)\n",
    "    return source_plates\n",
    "\n",
    "def make_gg_rxns(num_rxns,rxn_vol):\n",
    "    '''Calculates the amount of each reagent to add to reach the desired master mix'''\n",
    "    cutsmart = 1 * num_rxns\n",
    "    atp = 1 * num_rxns\n",
    "    vector = 0.25 * num_rxns\n",
    "    ligase = 0.5 * num_rxns\n",
    "    enzyme = 0.25 * num_rxns\n",
    "    water = (rxn_vol - ((cutsmart + atp + vector + ligase + enzyme)/num_rxns)) * num_rxns\n",
    "    master_mix = pd.DataFrame(\n",
    "        {'Component':['H2O','Cutsmart','ATP','Vector','T4 Ligase','Restriction Enzyme','Total'],\n",
    "        'Amount':[water,cutsmart,atp,vector,ligase,enzyme,rxn_vol*num_rxns]},\n",
    "        columns=[\"Component\",\"Amount\"]\n",
    "    )\n",
    "    return master_mix\n",
    "\n",
    "# # Verify that the correct robot is being used\n",
    "# if args.run:\n",
    "#     robot_name = str(os.environ[\"ROBOT_DEV\"][-5:])\n",
    "#     robot_number = str(input(\"Run on this robot: {} ? 1-Yes, 2-No \".format(robot_name)))\n",
    "#     if robot_number == \"1\":\n",
    "#         print(\"Proceeding with run\")\n",
    "#     else:\n",
    "#         sys.exit(\"Run roboswitch 'ROBOT_NAME' to change to the correct robot\")\n",
    "\n",
    "target_well = well_addresses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## =============================================\n",
    "## CREATE LIST OF DESIRED GENES\n",
    "## =============================================\n",
    "\n",
    "max_rxns = 96\n",
    "to_build = []\n",
    "acceptable_status = ['received']\n",
    "# to_build = [part for part in session.query(Part).filter(Part.status.in_(acceptable_status)).\\\n",
    "#                         order_by(Part.part_id).limit(max_rxns)]\n",
    "\n",
    "## Pulls in parts that have the desirable status and then sorts them by the plates their fragments are in,\n",
    "## sorts them by their plate numbers and returns the earliest set of parts\n",
    "to_build = [part for part in session.query(Part).join(Fragment,Part.fragments).\\\n",
    "            join(Well,Fragment.wells).join(Plate,Well.plates).\\\n",
    "            filter(Part.status.in_(acceptable_status)).filter(Plate.plate_name != 'pSHPs0807B412037MU').order_by(Plate.id)]\n",
    "to_build = to_build[:96]\n",
    "print(\"to build\",len(to_build))\n",
    "\n",
    "# unique_plates = []\n",
    "# for part in to_build:\n",
    "#     for frag in part.fragments:\n",
    "#         unique_plates.append(frag.wells[0].plates.plate_name)\n",
    "        \n",
    "# unique_plates = pd.Series(unique_plates).unique()\n",
    "# # print(unique_plates)\n",
    "\n",
    "# target_build = Build(to_build)\n",
    "# session.add(target_build)\n",
    "\n",
    "# Grabs the most recently entered build\n",
    "# target_build = session.query(Build).order_by(desc(Build.id)).first()\n",
    "\n",
    "# addresses = []\n",
    "# for plate in target_build.plates:\n",
    "#     print(plate.plate_name,plate.next_well)\n",
    "#     addresses.append([{'plate':well.plates.plate_name,'well':well.address,'frags':len(well.parts.fragments)}\\\n",
    "#                       for well in plate.wells if len(well.parts.fragments) > 1])\n",
    "# total_extra = 0\n",
    "# for plates in addresses:\n",
    "#     for transfer in plates:\n",
    "#         print(transfer['plate'],transfer['well'],transfer['frags'])\n",
    "#         total_extra += transfer['frags']\n",
    "# print(total_extra*8)\n",
    "\n",
    "# for well in session.query(Well).join(Part,Well.parts).join(Fragment,Part.fragments).filter(len(Fragment) > 1).limit(10):\n",
    "#     print(well.parts.part_id,well.address)\n",
    "\n",
    "\n",
    "\n",
    "# ## =============================================\n",
    "# ## CREATE PLATE GROUPS\n",
    "# ## =============================================\n",
    "# # Currently available spots on the OT-one deck\n",
    "# SOURCE_SLOTS = ['D2','D3','B2']\n",
    "\n",
    "# group_plates = [unique_plates[n:n+len(SOURCE_SLOTS)] for n in range(0, len(unique_plates), len(SOURCE_SLOTS))]\n",
    "# for num,group in enumerate(group_plates):\n",
    "#     print(\"Group{}: {}\".format(num+1,group))\n",
    "    \n",
    "# input(\"Press enter to continue\")\n",
    "\n",
    "# # Create a means to index to the plates\n",
    "# plate_dict = dict(enumerate(unique_plates))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the volume of master mix to use per reaction\n",
    "master_volume = 8\n",
    "# Set a multiplier to account for pipetting error and evaporation\n",
    "extra_master = 1.3\n",
    "\n",
    "need_extra = []\n",
    "for plate in target_build.plates:\n",
    "    # print(plate.plate_name,plate.next_well)\n",
    "    need_extra.append([{'plate':well.plates.plate_name,'well':well.address,'frags':len(well.parts.fragments)}\\\n",
    "                      for well in plate.wells if len(well.parts.fragments) > 1])\n",
    "total_extra = 0\n",
    "for plates in need_extra:\n",
    "    for transfer in plates:\n",
    "        print(transfer['plate'],transfer['well'],transfer['frags'])\n",
    "        total_extra += transfer['frags']\n",
    "num_reactions = len(to_build)\n",
    "master_reactions = (total_extra + num_reactions) * master_volume * extra_master\n",
    "print(total_extra)\n",
    "\n",
    "# Generate the dataframe to present the master mix composition\n",
    "master_mix = make_gg_rxns(master_reactions,master_volume)\n",
    "print(\"Use the table below to create the master mix\")\n",
    "print()\n",
    "print(master_mix)\n",
    "print()\n",
    "input(\"Press enter to continue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## =============================================\n",
    "## SETUP THE OT-1 DECK\n",
    "## =============================================\n",
    "# Specify the locations of each object on the deck\n",
    "locations = {\n",
    "            \"tiprack-200\" : \"A3\",\n",
    "            \"tiprack-10\" : \"E2\",\n",
    "            \"tiprack-10s1\" : \"E3\",\n",
    "            \"tiprack-10s2\" : \"E1\",\n",
    "            \"trash\" : \"D1\",\n",
    "            \"PCR-strip-tall\" : \"C3\",\n",
    "            \"DEST_PLATE\" : \"C2\",\n",
    "            \"Tube_rack\" : \"B1\"\n",
    "        }\n",
    "\n",
    "# Make the dataframe to represent the OT-1 deck\n",
    "deck = ['A1','B2','C3','D2','E1']\n",
    "slots = pd.Series(deck)\n",
    "columns = sorted(slots.str[0].unique())\n",
    "rows = sorted(slots.str[1].unique(), reverse=True)\n",
    "layout_table = pd.DataFrame(index=rows, columns=columns)\n",
    "layout_table.fillna(\"---\", inplace=True)\n",
    "\n",
    "# Fill in the data frame with the locations\n",
    "for obj in locations:\n",
    "        layout_table.loc[locations[obj][1], locations[obj][0]] = obj\n",
    "\n",
    "# Displays the required plate map and waits to proceed\n",
    "print(\"\\n Please arrange the items in the following configuration: \\n\")\n",
    "print(layout_table,\"\\n\")\n",
    "# input(\"Press enter to continue\")\n",
    "\n",
    "## =============================================\n",
    "## SETUP THE MASTER MIX\n",
    "## =============================================\n",
    "# Calculate how many reactions worth of MM to make\n",
    "total_num = 0\n",
    "for index, row in master.iterrows():\n",
    "    rxn_needed = int(row['Fragments'])\n",
    "    total_num += rxn_needed\n",
    "num_wells = len(master)\n",
    "print(\"wells\",num_wells)\n",
    "num_rows = num_wells // 8\n",
    "print('rows',num_rows)\n",
    "\n",
    "# Set a multiplier to account for pipetting error and evaporation\n",
    "extra_master = 1.3\n",
    "master_reactions = total_num * extra_master\n",
    "\n",
    "# Set the volume of master mix to use per reaction\n",
    "master_volume = 8\n",
    "\n",
    "# Generate the dataframe to present the master mix composition\n",
    "master_mix = make_gg_rxns(master_reactions,master_volume)\n",
    "print(\"Use the table below to create the master mix\")\n",
    "print()\n",
    "print(master_mix)\n",
    "print()\n",
    "# input(\"Press enter to continue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine,Column,Integer,String,ForeignKey,Table,Text,inspect\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker,relationship\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from config import *\n",
    "from db_config import *\n",
    "\n",
    "\n",
    "part1 = session.query(Part).filter(Part.part_id == 'BBF10K_000649').one()\n",
    "part2 = session.query(Part).filter(Part.part_name == 'MMSYN1_0648').one()\n",
    "print(part1.part_id,part1.fragments[0].fragment_name,part1.fragments[0].wells[0].address,part1.fragments[0].wells[0].plates.plate_name)\n",
    "print(part2.part_id,part2.fragments[0].fragment_name,part2.fragments[0].wells[0].address,part2.fragments[0].wells[0].plates.plate_name)\n",
    "\n",
    "# build = session.query(Build).filter(Build.build_name == 'build009').one()\n",
    "# for plate in build.plates:\n",
    "#     for well in plate.wells:\n",
    "#         print(well.parts.part_id,well.address,well.parts.status)\n",
    "\n",
    "# for instance in session.query(Part).join(Well,Part.wells).join(Plate,Wells.plates).filter(Plate.plate_type == 'syn_plate').filter(Well.volume == None).order_by(Plate.id):\n",
    "#     print(instance.plate_name)\n",
    "\n",
    "# for instance in session.query(Plate):#.join(Well,Plate.wells).filter(Plate.plate_type == 'syn_plate').filter(Well.volume == None).order_by(Plate.id):\n",
    "#     print(instance.plate_name)\n",
    "#     for well in instance.wells:\n",
    "#         print(well.address,well.syn_yield,well.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plate = session.query(Plate).filter(Plate.plate_name == 'pSHPs1207B618708MU').one()\n",
    "plate = session.query(Plate).filter(Plate.plate_name == 'pSHPs0807B412037MU').one()\n",
    "\n",
    "print(plate.plate_name,len(plate.wells))\n",
    "for well in plate.wells:\n",
    "    print(well.fragments.fragment_name,well.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine,Column,Integer,String,ForeignKey,Table,Text,inspect\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker,relationship\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from config import *\n",
    "from db_config import *\n",
    "\n",
    "def well_addresses():\n",
    "    '''Generates a list of well address A1-H12'''\n",
    "    letter = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\"]\n",
    "    number = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\"]\n",
    "    target_well = []\n",
    "    temp_well = 0\n",
    "    for n in number:\n",
    "        for l in letter:\n",
    "            temp_well = l + n\n",
    "            target_well.append(temp_well)\n",
    "    return target_well\n",
    "\n",
    "wells = well_addresses()\n",
    "\n",
    "\n",
    "names = []\n",
    "id_nums = []\n",
    "for file in sorted(glob.glob(\"{}/data/*/*.json\".format(BASE_PATH))):\n",
    "    with open(file,\"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "    names.append(data['info']['documentation']['gene_name'])\n",
    "    id_nums.append(data['gene_id'])\n",
    "dictionary = dict(zip(names,id_nums))\n",
    "print(dictionary)\n",
    "\n",
    "## Build a list of the previously entered synthesis plates\n",
    "plates_made = [plate.plate_name for plate in session.query(Plate).filter(Plate.plate_type == 'syn_plate')]\n",
    "print(\"Plates that have already been parsed:\\n\",plates_made)\n",
    "\n",
    "## Take in the previous list of fragments that weren't placed\n",
    "if glob.glob('{}/raw_files/not_found.json'.format(BASE_PATH)):\n",
    "    with open('{}/raw_files/not_found.json'.format(BASE_PATH),'r') as json_file:\n",
    "        not_found = json.load(json_file)\n",
    "else:\n",
    "    not_found = {}\n",
    "    \n",
    "## Take in plate maps from twist and generate fragment objects\n",
    "for file in glob.glob('{}/plate_maps/*.csv'.format(BASE_PATH)):\n",
    "    plate_map = pd.read_csv(file)\n",
    "    ## Have to account for two different csv formats\n",
    "    try:\n",
    "        plate_map['Plate']\n",
    "        version = 1\n",
    "        plate_key = 'Plate'\n",
    "        well_key = 'Well'\n",
    "        name_key = 'customer_line_item_id'\n",
    "        sequence_key = 'Insert Sequence'\n",
    "    except:\n",
    "        try:\n",
    "            plate_map['Plate ID']\n",
    "            version = 2\n",
    "            plate_key = 'Plate ID'\n",
    "            well_key = 'Well Location'\n",
    "            name_key = 'Name'\n",
    "            sequence_key = 'Insert sequence'\n",
    "        except:\n",
    "            print(\"Doesn't fit the standard formats\")\n",
    "    unique = plate_map[plate_key].unique()\n",
    "    for plate in unique:\n",
    "        # Create a subset of rows pertaining to a specific plate\n",
    "        current_plate_map = plate_map[plate_map[plate_key] == plate]\n",
    "        current_plate = Plate('','syn_plate',plate_name=plate)\n",
    "        session.add(current_plate)\n",
    "        current_missing = []\n",
    "        for index,row in current_plate_map.iterrows():\n",
    "            current_frag = ''\n",
    "            current_frag = session.query(Fragment).filter(Fragment.seq == row[sequence_key]).first()\n",
    "            # Checks if a corresponding fragment is found and then adds it to the plate\n",
    "            if current_frag:\n",
    "                current_plate.add_item(current_frag,row[well_key].strip(),syn_yield=row['Yield (ng)'])\n",
    "            else:\n",
    "                current_missing.append(row[name_key].strip())\n",
    "                print(row[name_key].strip())\n",
    "                print(row[sequence_key])\n",
    "                print(len(row[sequence_key]))\n",
    "        current_missing = {plate : current_missing}\n",
    "        print(current_missing)\n",
    "        not_found.update(current_missing)\n",
    "\n",
    "## Write the new fragments that were not placed to a file\n",
    "with open('{}/raw_files/not_found.json'.format(BASE_PATH),'w+') as json_file:\n",
    "    json.dump(not_found,json_file,indent=2)\n",
    "print(not_found)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fluc = 'GAAGACATAATGGAAAAGGAGGAGAATGTTGTGTATGGCCCTCTGCCATTCTACCCCATTGAAGAAGGATCAGCTGGAATCCAGTTGCATAAGTACATGCATCAATATGCCAAACTTGGAGCAATTGCTTTTTCCAACGCCCTTACCGGTGTTGACATTTCTTACCAAGAATACTTTGATATTACATGTCGCTTGGCTGAAGCCATGAAAAACTTTGGCATGAAACCTGAAGAACATATTGCTTTGTGCAGTGAAAATTGTGAAGAATTCTTCATCCCTGTTCTTGCTGGTCTTTATATTGGGGTTGCTGTTGCACCTACTAATGAAATTTACACATTGCGCGAACTTAATCATTGTTTGGGTATCGCACAACCAACTATTGTATTCAGCAGCAGAAAAGGCTTACCCAAAGTTTTAGAAGTGCAGAAAACAGTTACAAGCATCAAGAAAATTGTTATTTTAGATAGTAGAGTAAACTTTGGGGGCCACGATTGTATGGAAACTTTTATTAAGAAACACGTAGAACTTGGTTTTCAACCATCAAGCTTTGTACCCATTGATGTTAAGAATCGCAAACAACACGTTGCTTTGCTTATGAACTCATCTGGCTCTACTGGTTTACCTAAAGGTGTACTTATTAGCCACGAAGGTGTAGTTACAAGACTCTCACACGCTAAGGATCCAATTTACGGAAACCAAGTTTCCCCTGGTACTGCTATTTTAACTGTCGTTCCATTCCATCATGGATTTGGAATGTTTACCACTTTAGGATACTTTGCTTGTGGATACCGCGTTGTAATGTTAACAAAATTTGATGAAGAACTGTTTTTGAGAACTTTGCAAGATTATAAGTGTACAAGTGTTATTCTGGTACCAACATTATTGGCTATTCTCAACAAGAGTGAATTGATCGATAAGTTCGATTTATCTAATCTTACTGAAATTGCTTCTGGTGGAGCTCCTTTGGCAAAAGAAGTTGGCGAAGCAGTCGCACGCCGCTTTAATCTTCCCGGTGTCCGCCAGGGTTACGGATTAACAGAAACTACATCTGCATTTATTATTACCCCAAAAGGTGATAATAAACCTGGAGCATGTGGAAAAGTTGTACCCCTTTTCAAAGTTAAAGTTATTGATCTTGACACTAAGAAAACTTTGGGTGTCAATCGCCGCGGAGAAATCTGTGTAAAGGGCCCAGGTCTTATGTTAGGCTACTCCAACAATCCAGAAGCAACAAGAGAAATTATTGATGAAGAGGGTTGGTTGCACACAGGAGATATTGGATATTACGACGAGGACGAACATTTCTTCATTGTCGACCGCTTGAAATCATTAATCAAATACAAGGGGTACCAGGTACCTCCTGCTGAATTGGAATCCGTTCTTCTGCAGCATCCAAATATTTTTGATGCTGGTGTGGCTGGTGTCCCCGATCCCGATGCTGGCGAACTTCCAGGCGCCGTTGTTGTAATGGAAAAAGGAAAAACTATGACTGAAAAGGAAATTGTGGATTATGTTAATAGTCAAGTAGTGGACCACAAACGCTTGCGCGGTGGCGTTCGCTTTGTGGATGAAGTACCTAAAGGTCTTACTGGTAAAATTGATGCTAAAGTAATTAGAGAGATCTTGAAGAAACCACAAAGTGGCCCACTCGAGTGAATCGTCTTC'\n",
    "print(len(Fluc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "string = '/codon_start=1/transl_table=11/gene=\"ribF\"/gene_synonym=\"ECK0026; JW0023; yaaC\"/locus_tag=\"b0025\"/product=\"bifunctional riboflavin kinase/FAD synthetase\"/function=\"putative regulator; Not classified\"/EC_number=\"2.7.1.26;2.7.7.2\"/label=ribF/db_xref=\"GI:16128019\"/db_xref=\"ASAP:ABE-0000091\"/db_xref=\"UniProtKB/Swiss-Prot:P0AG40\"/db_xref=\"EcoGene:EG11079\"/db_xref=\"GeneID:949129\"/protein_id=\"NP_414566.1\"/translation=\"MKLIRGIHNLSQAPQEGCVLTIGNFDGVHRGHRALLQGLQEEGRKRNLPVMVMLFEPQPLELFATDKAPARLTRLREKLRYLAECGVDYVLCVRFDRRFAALTAQNFISDLLVKHLRVKFLAVGDDFRFGAGREGDFLLLQKAGMEYGFDITSTQTFCEGGVRISSTAVRQALADDNLALAESLLGHPFAISGRVVHGDELGRTIGFPTANVPLRRQVSPVKGVYAVEVLGLGEKPLPGVANIGTRPTVAGIRQQLEVHLLDVAMDLYGRHIQVVLRKKIRNEQRFASLDELKAQIARDELTAREFFGLTKPA\" /GenBank_acc=\"NC_000913\"; /Source=\"Escherichia coli str. K-12 substr. MG1655\"; /feature_type=\"CDS\"; /strand=\"+\";'\n",
    "references = re.findall(r'(db_xref=\\\"[A-Za-z0-9:_/-]+\\\")',string)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
